<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Purdue CNIT581-RDM: Responsible Data Management</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script>
      function toggle(id) {
      var e = document.getElementById(id);
      e.style.display = (e.style.display == 'block') ? 'none' : 'block';
    }
    </script>
    <link rel = "icon" href = "https://www.purdue.edu/purdue/images/favicon.ico" type = "image/x-icon">
    <link rel = "icon" href = "https://www.purdue.edu/purdue/images/favicon.ico" type = "shortcut icon">
  </head>
  <body>
    <div class="wrapper">
      <header>
        <b><font size=3em>Purdue CNIT581-RDM: Responsible Data Management</font></b><br>
        Spring 2023<br>
        <br>
        Computer & Information Technology<br>
        Purdue University<br>
        </p>
        
        <b>TL;DR:</b> Interested in data management and/or machine learning? <br>
        Consider taking CNIT 58100-RDM in Spring 2023. <br>

        <br><b>Questions?</b> 
        <br>Send an email to the instructor 
        <br>at <a href="mailto:">rpradhan@purdue.edu</a>
      </header>

      <section>
        <h2>COURSE OVERVIEW</h2>
        <p>Responsible data management (RDM) is a fast-growing research area focused on responsible data handling practices in data-driven decision-making systems. Research in this area is centered around the transparency of data, algorithms, and data science (DS) pipelines. </p>
 
        <p>This course examines advanced topics relating to algorithmic fairness, transparency, and interpretability of data-driven decision-making systems. We will study current issues related to the transparency and fairness of data-driven decisions, examine sources of unexpected and discriminatory behavior of data-driven decision-making systems and contrast existing methods and design novel techniques to mitigate undesired system decisions. Topics include algorithmic bias, fairness metrics, debugging and mitigating bias/errors, interpretability of algorithms, the data science lifecycle and bias in the DS pipelines.</p>

        <p><b>When:</b> TR 3:00 - 4:15 PM</p> 
        <p><b>Where:</b> KNOY Hall, Room B031</p> 

        <p><b>Lecture style:</b> The lectures will be a mix of traditional lectures, paper readings/presentations and practical problem solving, discussing responsible data management from different aspects. As a side goal, we will identify potential open problems for further research.</p>
        
        <p><b>Prerequisites:</b> Any undergraduate data management course and exposure to machine learning.</p> 

        <div id="instructor">
        <h2>INSTRUCTOR</h2>
        Romila Pradhan<a href="https://romilapradhan.github.io"> (Homepage)</a> 
        <br>Email: <a href="mailto:">rpradhan@purdue.edu</a>

        <div id="evaluation">
        <h2>EVALUATION</h2>
        There will be 2-3 assignments followed by a semester-long project chosen by the student. Each student is also expected to present 2-3 research presentations. The project will be a group project 

        Students will be evaluated as follows: 
        <ul>
          <li> Project (40%): proposal + initial draft (5%), presentation (15%), report (20%)</li>
          <li> In-class paper presentations (25%): 2-3 in-class presentations</li>
          <li> Assignments (25%): 2-3</li>
          <li> Participation (10%): In-class discussions on presented papers</li>
        </ul>

        <div id="project">
        <h2>COURSE PROJECT</h2>
        For the course project, you will work (individually or in teams of 2) to produce a research paper and present a research talk during the final weeks of the course. The project description will be provided in the second week of classes.

        There are three submissions for the class project: the initial project proposal, a draft of the paper, the final paper, and the final talk. The initial project proposal and partial paper will be submitted primarily for feedback from the instructor.

        <div id="schedule">
        <h2>TENTATIVE SCHEDULE</h2>
          <ul>
            <li> Week 1: Introduction and background</li>
            <li> Week 2: Algorithmic fairness</li>
            <li> Week 3: Data science lifecycle and bias in data science pipelines</li>
            <li> Weeks 4-5: Fairness metrics</li>
            <li> Weeks 6-7: Bias mitigation techniques</li>
            <li> Weeks 7-9: Explainability and interpretability of ML models</li>
            <li>Week 10: SPRING BREAK</li>
            <li> Weeks 11-15: Debugging ML models and pipelines </li>
            <li> Week 16: Data management challenges in production ML; Project presentations</li>
          </ul>
        </div>

        <div id="schedule">
        <h2>LIST OF PAPERS</h2>
            Week 1: Introduction and background
            <ul>
              <li>Julia Stoyanovich, Serge Abiteboul, Bill Howe, H. V. Jagadish, and Sebastian Schelter. 2022. <a href="https://dl.acm.org/doi/10.1145/3488717">Responsible Data Management</a>. Communications of the ACM.</li>
              <li>Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner. 2016. <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Machine Bias.</a> Propublica.</li>
            </ul>

            Week 2: Algorithmic fairness
            <ul>
              <li>Ramya Srinivasan and Ajay Chander. 2021. <a href="https://doi.org/10.1145/3466132.3466134">Biases in AI Systems: A survey for practitioners</a>. ACM Queue.</li>
              <li>Batya Friedman and Helen Nissenbaum. 1996. <a href="https://doi.org/10.1145/230538.230561">Bias in computer systems</a>. ACM Transactions on Information Systems.</li>
            </ul>

            Week 3: Data science lifecycle and bias in data science pipelines
            <ul>
              <li>Jeanette. M. Wing. 2019. <a href="https://doi.org/10.1162/99608f92.e26845b4">The Data Life Cycle</a>. Harvard Data Science Review</li>
              <li>Sumon Biswas, Mohammad Wardat, and Hridesh Rajan. 2022. <a href="https://doi.org/10.1145/3510003.3510057">The art and practice of data science pipelines: A comprehensive study of data science pipelines in theory, in-the-small, and in-the-large</a>. In Proceedings of the 44th International Conference on Software Engineering (ICSE '22)</li>
            </ul>

            Weeks 4-5: Fairness metrics
            <ul>
              <li>Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. <a href="https://doi.org/10.1145/3457607">A Survey on Bias and Fairness in Machine Learning</a>. ACM Computing Surveys.</li>
              <li>Sahil Verma and Julia Rubin. 2018. <a href="https://fairware.cs.umass.edu/papers/Verma.pdf">Fairness Definitions Explained</a>. 2018 ACM/IEEE International Workshop on Software Fairness.</li>
              <li>Dana Pessach and Erez Shmueli. 2022. <a href="https://doi.org/10.1145/3494672">A Review on Fairness in Machine Learning</a>. ACM Computing Surveys. (Sections 1 through 3)</li>
            </ul>
           
            Week 6: Bias mitigation techniques (pre-processing)
            <ul>
              <li>Faisal Kamiran and Toon Calders. 2012. <a href="https://doi.org/10.1007/s10115-011-0463-8">Data preprocessing techniques for classification without discrimination</a>. Knowledge and Information Systems.</li>
              <li>Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. <a href="https://doi.org/10.1145/2783258.2783311">Certifying and Removing Disparate Impact</a>. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '15).</li>
              <li>Zemel, R., Wu, Y., Swersky, K., Pitassi, T. &amp; Dwork, C.. 2013. <a href="https://proceedings.mlr.press/v28/zemel13.html">Learning Fair Representations</a>. <i>Proceedings of the 30th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> </li>
              <li>Babak Salimi, Luke Rodriguez, Bill Howe, and Dan Suciu. 2019. <a href="https://doi.org/10.1145/3299869.3319901">Interventional Fairness: Causal Database Repair for Algorithmic Fairness</a>. In Proceedings of the 2019 International Conference on Management of Data (SIGMOD '19).</li>
            </ul>

            Week 7: Bias mitigation techniques (in-processing + post-processing)
            <ul>
              <li>Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P. Gummadi. 2017. <a href="https://doi.org/10.1145/3038912.3052660">Fairness Beyond Disparate Treatment &amp; Disparate Impact: Learning Classification without Disparate Mistreatment</a>. In Proceedings of the 26th International Conference on World Wide Web (WWW '17). </li>
              <li>Moritz Hardt, Eric Price, and Nathan Srebro. 2016. <a href="https://papers.nips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html">Equality of opportunity in supervised learning</a>. In Proceedings of the 30th International Conference on Neural Information Processing Systems (NIPS'16). </li>
              <li>Dwork, C., Immorlica, N., Kalai, A.T. &amp; Leiserson, M.. (2018). <a href="https://proceedings.mlr.press/v81/dwork18a.html">Decoupled Classifiers for Group-Fair and Efficient Machine Learning</a>. <i>Proceedings of the 1st Conference on Fairness, Accountability and Transparency</i>, in <i>Proceedings of Machine Learning Research</i></li>
            </ul>

            Week 8: Explainability and interpretability of ML models (feature-based, data-based)
            <ul>
              <li>Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. <a href="https://doi.org/10.1145/2939672.2939778">Why Should I Trust You?": Explaining the Predictions of Any Classifier</a>. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16). </li>
              <li>Scott M. Lundberg and Su-In Lee. 2017. <a href="https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf">A unified approach to interpreting model predictions</a>. In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS'17).</li>
              <li>Sainyam Galhotra, Romila Pradhan, and Babak Salimi. 2021. <a href="https://doi.org/10.1145/3448016.3458455">Explaining Black-Box Algorithms Using Probabilistic Contrastive Counterfactuals</a>. In Proceedings of the 2021 International Conference on Management of Data (SIGMOD '21).</li>
              <li>Koh, P.W. &amp; Liang, P.. (2017). <a href="https://proceedings.mlr.press/v70/koh17a.html">Understanding Black-box Predictions via Influence Functions</a>. <i>Proceedings of the 34th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i>.</li>
            </ul>

            Week 9: Explainability and interpretability of ML models (data-based)
            <ul>
              <li>Ghorbani, A. &amp; Zou, J.. (2019). <a href="https://proceedings.mlr.press/v97/ghorbani19c.html">Data Shapley: Equitable Valuation of Data for Machine Learning</a>. <i>Proceedings of the 36th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i></li>
              <li>Romila Pradhan, Jiongli Zhu, Boris Glavic, and Babak Salimi. 2022. <a href="https://doi.org/10.1145/3514221.3517886">Interpretable Data-Based Explanations for Fairness Debugging</a>. In Proceedings of the 2022 International Conference on Management of Data (SIGMOD '22).</li>
            </ul>

            Week 10: SPRING BREAK<br><br>
            
            Week 11: Debugging ML models and pipelines (model performance)
            <ul>
              <li>Chung, Y., Kraska, T., Polyzotis, N., Tae, K. H., & Whang, S. E. 2019. <a href="https://research.google/pubs/pub47966/">Slice finder: Automated data slicing for model validation</a>. In 2019 IEEE 35th International Conference on Data Engineering (ICDE).</li>
              <li>Weiyuan Wu, Lampros Flokas, Eugene Wu, and Jiannan Wang. 2020. <a href="https://doi.org/10.1145/3318464.3389696">Complaint-driven Training Data Debugging for Query 2.0</a>. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data (SIGMOD '20).</li>
              <!-- <li>DiffML: End-to-end Differentiable ML Pipelines</li> -->
              <li>Laure Berti-Equille. 2019. <a href="https://doi.org/10.1145/3308558.3313602">Learn2Clean: Optimizing the Sequence of Tasks for Web Data Preparation</a>. In The World Wide Web Conference (WWW '19).</li>
              <li>Yanhui Li, Linghan Meng, Lin Chen, Li Yu, Di Wu, Yuming Zhou, and Baowen Xu. 2022. <a href="https://doi.org/10.1145/3510003.3510091">Training data debugging for the fairness of machine learning software</a>. In Proceedings of the 44th International Conference on Software Engineering (ICSE '22). </li>
            </ul>

            Week 12: Debugging ML models and pipelines (model performance)
            <ul>
              <li>Junwen Yang, Yeye He, and Surajit Chaudhuri. 2021. <a href="https://doi.org/10.14778/3476249.3476303">Auto-pipeline: synthesizing complex data pipelines by-target using reinforcement learning and search</a>. Proceedings of the VLDB Endowment.</li>
              <li>Robin Cugny, Julien Aligon, Max Chevalier, Geoffrey Roman Jimenez, and Olivier Teste. 2022. <a href="https://doi.org/10.1145/3511808.3557247">AutoXAI: A Framework to Automatically Select the Most Adapted XAI Solution</a>. In Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management (CIKM '22).</li>
              <li>Raoni Lourenço, Juliana Freire, and Dennis Shasha. 2020. <a href="https://doi.org/10.1145/3318464.3389763">BugDoc: Algorithms to Debug Computational Processes</a>. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data (SIGMOD '20).</li>
            </ul>

            Week 13: Debugging ML models and pipelines (model performance, data acquisition)
            <ul>
              <li>Ki Hyun Tae and Steven Euijong Whang. 2021. <a href="https://doi.org/10.1145/3448016.3452792">Slice Tuner: A Selective Data Acquisition Framework for Accurate and Fair Machine Learning Models</a>. In Proceedings of the 2021 International Conference on Management of Data (SIGMOD '21).</li>
              <li>A. Asudeh, Z. Jin and H. V. Jagadish. 2019. <a href="https://doi.org/10.1109/ICDE.2019.00056.">Assessing and Remedying Coverage for a Given Dataset</a>. IEEE 35th International Conference on Data Engineering (ICDE).</li>
              <li>Chengliang Chai, Jiabin Liu, Nan Tang, Guoliang Li, and Yuyu Luo. 2022. <a href="https://doi.org/10.14778/3523210.3523223">Selective data acquisition in the wild for model charging</a>. Proceedings of the VLDB Endowment.</li>
              <li>Sainyam Galhotra, Anna Fariha, Raoni Lourenço, Juliana Freire, Alexandra Meliou, and Divesh Srivastava. 2022. <a href="https://doi.org/10.1145/3514221.3517864">DataPrism: Exposing Disconnect between Data and Systems</a>. In Proceedings of the 2022 International Conference on Management of Data (SIGMOD '22).</li>
            </ul>

            Week 14: Debugging ML models and pipelines (impact of data preprocessing)
            <ul>
              <li>Sumon Biswas and Hridesh Rajan. 2021. <a href="https://doi.org/10.1145/3468264.3468536">Fair preprocessing: towards understanding compositional fairness of data transformers in machine learning pipeline</a>. In Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2021).</li>
              <li>Sainyam Galhotra, Karthikeyan Shanmugam, Prasanna Sattigeri, and Kush R. Varshney. 2022. <a href="https://doi.org/10.1145/3514221.3517909">Causal Feature Selection for Algorithmic Fairness</a>. In Proceedings of the 2022 International Conference on Management of Data (SIGMOD '22).</li>
              <li>Nianyun Li, Naman Goel, and Elliott Ash. 2022. <a href="https://doi.org/10.1145/3514094.3534147">Data-Centric Factors in Algorithmic Fairness</a>. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES '22).</li>
              <li>Yiqiao Liao and Parinaz Naghizadeh. 2023. <a href="https://arxiv.org/pdf/2206.00137.pdf">Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria</a>. To appear in Proceedings of AAAI 2023.</li>
            </ul>

            Week 15: Debugging ML models and pipelines (impact of data cleaning)
            <ul>
              <li>Sanjay Krishnan, Michael J. Franklin, Ken Goldberg, and Eugene Wu. 2017. <a href="https://arxiv.org/pdf/1711.01299.pdf">BoostClean: Automated Error Detection and Repair for Machine Learning</a>. arXiV.</li>
              <li>Sanjay Krishnan, Jiannan Wang, Eugene Wu, Michael J. Franklin, and Ken Goldberg. 2016. <a href="https://doi.org/10.14778/2994509.2994514">ActiveClean: interactive data cleaning for statistical modeling</a>. Proceedings of the VLDB Endowment.</li>
              <li>Maliha Tashfia Islam, Anna Fariha, Alexandra Meliou, and Babak Salimi. 2022. <a href="https://doi.org/10.1145/3514221.3517841">Through the Data Management Lens: Experimental Analysis and Evaluation of Fair Classification</a>. In Proceedings of the 2022 International Conference on Management of Data (SIGMOD '22).</li>
              <li>Lukas Budach, Moritz Feuerpfeil, Nina Ihde, Andrea Nathansen, Nele Noack, Hendrik Patzlaff, Felix Naumann, and Hazar Harmouch. <a href="https://arxiv.org/pdf/2207.14529.pdf">The Effects of Data Quality on Machine Learning Performance</a>. arXiV.</li>
              <li>Felix Neutatz, Binger Chen, Yazan Alkhatib, Jingwen Ye & Ziawasch Abedjan. 2022. <a href="https://doi.org/10.1007/s13222-022-00413-2">Data Cleaning and AutoML: Would an Optimizer Choose to Clean?</a>. Datenbank Spektrum. </li>
            </ul>

            Week 16: Data management challenges in ML pipelines
            <ul>
              <li>Steven Euijong Whang, Yuji Roh, Hwanjun Song & Jae-Gil Lee. 2023. <a href="https://doi.org/10.1007/s00778-022-00775-9">Data Collection and Quality Challenges in Deep Learning: A Data-Centric AI Perspective</a>. The VLDB Journal.</li>
              <li>Y. Roh, G. Heo and S. E. Whang. 2021. <a href="https://ieeexplore.ieee.org/document/8862913">A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective</a>. IEEE Transactions on Knowledge and Data Engineering.</li>
              <li>Neoklis Polyzotis, Sudip Roy, Steven Euijong Whang, and Martin Zinkevich. 2017. <a href="https://doi.org/10.1145/3035918.3054782">Data Management Challenges in Production Machine Learning</a>. In Proceedings of the 2017 ACM International Conference on Management of Data (SIGMOD '17).</li>
            </ul>
        </div>
  </body>
</html>
